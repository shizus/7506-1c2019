{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparo los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs = pd.read_csv('../datos/installs.csv', dtype ={'device_language' : 'str', 'click_hash': object, 'wifi': object, 'trans_id': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tiene sentido quedarse con el pais, porque es uno solo\n",
    "#No tiene sentido quedarse con la columna trans_id. El 98% de los valores son Null\n",
    "#No tiene sentido quedarse con click_hash, el 99% de los valors son null\n",
    "#No tiene sentido quedarse con event_uuid, el 78% de los valores son null\n",
    "#No tiene sentido quedarse con kind, el 78% de los valores son null\n",
    "#No tiene sentido quedarse con wifi, el 48% de los valores son null\n",
    "#No tiene sentido quedarse con device_brand. El 42% son null\n",
    "#No tiene sentido quedarse con la columna user_agent El 31% de los valores son Null\n",
    "#¿Tiene sentido quedarse con la columna session_user_agent? El 3% de los valores son Null\n",
    "# session_user_agent tiene el 3% de los valores null. Borro esas filas\n",
    "del installs['trans_id']\n",
    "del installs['device_countrycode']\n",
    "del installs['click_hash']\n",
    "del installs['event_uuid']\n",
    "del installs['kind']\n",
    "del installs['wifi']\n",
    "del installs['device_brand']\n",
    "del installs['user_agent']\n",
    "del installs['session_user_agent']\n",
    "\n",
    "##Borro las filas que tienen null en device_model y device_language. Juntas son el 5% de las filas en null\n",
    "installs = installs[pd.notnull(installs['device_model'])]\n",
    "installs = installs[pd.notnull(installs['device_language'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['created'] = pd.to_datetime(installs['created'], errors = 'coerce')\n",
    "installs = installs.sort_values(by = ['ref_hash', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('../datos/events.csv',\n",
    "                     dtype={\n",
    "                         'device_countrycode': 'category', \n",
    "                         'device_city': 'category',\n",
    "                         'ref_type': 'int64',\n",
    "                         'application_id': 'int64',\n",
    "                         'device_os_version': 'category',\n",
    "                         'device_brand': 'category',\n",
    "                         'device_model': 'float64',\n",
    "                         'session_user_agent': 'category',\n",
    "                         'trans_id': 'category',\n",
    "                         'user_agent': 'category',\n",
    "                         'carrier': 'category',\n",
    "                         'device_os': 'category',\n",
    "                         'device_os_version': 'category',\n",
    "                         'device_language': 'category',\n",
    "                         'connection_type': 'category',\n",
    "                         'wifi': 'bool'\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del events['attributed']\n",
    "del events['device_countrycode'] #Borrada porque hay un solo país\n",
    "del events['trans_id'] #Borrada por tener muy pocos valores (37000/7000000)\n",
    "del events['event_uuid'] #Borrada por tener todos los valores distintos\n",
    "del events['device_os_version'] #Borrado por tener 70% de los valores nulos.\n",
    "del events['device_brand'] #Borrado por tener 67% de los valores nulos\n",
    "del events['device_city'] #Borrado por tener 76% de los valores nulos\n",
    "del events['user_agent'] #Borrado por tener 57% de los valores nulos\n",
    "del events['carrier'] #Borrado por tener 75% de los valores nulos\n",
    "del events['device_os'] #Borrado por tener 76% de los valores nulos\n",
    "del events['connection_type'] #Borrado por tener 77% de los valores nulos\n",
    "del events['session_user_agent']\n",
    "#------------------------------------------------------------------\n",
    "events = events[pd.notnull(events['kind'])] #Borrados las filas nulas (0,5%)\n",
    "#------------------------------------------------------------------\n",
    "events = events[pd.notnull(events['device_model'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348229"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['ref_hash'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373799"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installs['ref_hash'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>application_id</th>\n",
       "      <th>ref_type</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>attributed</th>\n",
       "      <th>implicit</th>\n",
       "      <th>device_model</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>device_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46742</th>\n",
       "      <td>2019-04-21 19:17:47.657</td>\n",
       "      <td>77</td>\n",
       "      <td>1891515180541284343</td>\n",
       "      <td>40621409780134</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.019322e+18</td>\n",
       "      <td>990380024993756535</td>\n",
       "      <td>3.3013777759776993e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398921</th>\n",
       "      <td>2019-04-18 21:11:50.326</td>\n",
       "      <td>121</td>\n",
       "      <td>1891515180541284343</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.658417e+18</td>\n",
       "      <td>7530145772806895848</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249204</th>\n",
       "      <td>2019-04-18 21:11:51.966</td>\n",
       "      <td>121</td>\n",
       "      <td>1891515180541284343</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.658417e+18</td>\n",
       "      <td>7530145772806895848</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112218</th>\n",
       "      <td>2019-04-18 21:17:11.946</td>\n",
       "      <td>65</td>\n",
       "      <td>1891515180541284343</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.658417e+18</td>\n",
       "      <td>7530145772806895848</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112200</th>\n",
       "      <td>2019-04-18 21:17:16.531</td>\n",
       "      <td>65</td>\n",
       "      <td>1891515180541284343</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.658417e+18</td>\n",
       "      <td>7530145772806895848</td>\n",
       "      <td>6.977049253562486e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created  application_id             ref_type  \\\n",
       "46742  2019-04-21 19:17:47.657              77  1891515180541284343   \n",
       "398921 2019-04-18 21:11:50.326             121  1891515180541284343   \n",
       "249204 2019-04-18 21:11:51.966             121  1891515180541284343   \n",
       "112218 2019-04-18 21:17:11.946              65  1891515180541284343   \n",
       "112200 2019-04-18 21:17:16.531              65  1891515180541284343   \n",
       "\n",
       "              ref_hash  attributed  implicit  device_model  \\\n",
       "46742   40621409780134       False     False  2.019322e+18   \n",
       "398921  41863526108385       False      True  1.658417e+18   \n",
       "249204  41863526108385       False     False  1.658417e+18   \n",
       "112218  41863526108385       False     False  1.658417e+18   \n",
       "112200  41863526108385       False      True  1.658417e+18   \n",
       "\n",
       "                 ip_address         device_language  \n",
       "46742    990380024993756535  3.3013777759776993e+18  \n",
       "398921  7530145772806895848   6.977049253562486e+18  \n",
       "249204  7530145772806895848   6.977049253562486e+18  \n",
       "112218  7530145772806895848   6.977049253562486e+18  \n",
       "112200  7530145772806895848   6.977049253562486e+18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos = events.groupby('ref_hash').agg({'wifi' : 'mean', 'application_id' : 'count', 'kind' : 'nunique', 'event_id' : 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['mode_model'] = events.groupby('ref_hash')['device_model'].agg(lambda x: x.value_counts().index[0])\n",
    "events['mode_lang'] = events.groupby('ref_hash')['device_language'].agg(lambda x: x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['total_apps'] = installs.groupby('ref_hash')['application_id'].transform('count')\n",
    "installs['%implicit'] = installs.groupby('ref_hash')['implicit'].transform('mean')\n",
    "installs['%attributed'] = installs.groupby('ref_hash')['attributed'].transform('mean')\n",
    "installs['most_freq_lang'] = installs.groupby('ref_hash')['device_language'].transform(lambda x: x.mode().iloc[0])\n",
    "installs['most_freq_app'] = installs.groupby('ref_hash')['application_id'].transform(lambda x: x.mode().iloc[0])\n",
    "installs['model'] = installs.groupby('ref_hash')['device_model'].transform(lambda x: x.mode().iloc[0])\n",
    "installs['ip'] = installs.groupby('ref_hash')['ip_address'].transform(lambda x: x.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['events_%wifi'] = installs['ref_hash'].map(eventos.set_index('ref_hash')['wifi'])\n",
    "installs['event_apps'] = installs['ref_hash'].map(eventos.set_index('ref_hash')['application_id'])\n",
    "installs['distinct_events'] = installs['ref_hash'].map(eventos.set_index('ref_hash')['kind'])\n",
    "installs['total_events'] = installs['ref_hash'].map(eventos.set_index('ref_hash')['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del installs['attributed']\n",
    "del installs['implicit']\n",
    "del installs['application_id']\n",
    "del installs['device_model']\n",
    "del installs['ip_address']\n",
    "del installs['device_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "installs.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs = installs.sort_values(by = ['ref_hash', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['most_freq_lang'] = installs['most_freq_lang'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs1 = installs[(installs['created'].dt.day < 21)]\n",
    "installs2 = installs[(installs['created'].dt.day > 18) & (installs['created'].dt.day < 22)]\n",
    "installs3 = installs[(installs['created'].dt.day > 19) & (installs['created'].dt.day < 23)]\n",
    "installs4 = installs[(installs['created'].dt.day > 20) & (installs['created'].dt.day < 24)]\n",
    "installs5 = installs[(installs['created'].dt.day > 21) & (installs['created'].dt.day < 25)]\n",
    "installsCheck1 = installs[(installs['created'].dt.day > 20) & (installs['created'].dt.day < 23)]\n",
    "installsCheck2 = installs[(installs['created'].dt.day > 21) & (installs['created'].dt.day < 24)]\n",
    "installsCheck3 = installs[(installs['created'].dt.day > 22) & (installs['created'].dt.day < 25)]\n",
    "installsCheck4 = installs[(installs['created'].dt.day > 23) & (installs['created'].dt.day < 26)]\n",
    "installsCheck5 = installs[(installs['created'].dt.day > 24) & (installs['created'].dt.day < 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs1['sc'] = (installs1['created'] - pd.to_datetime('2019-04-18'))/np.timedelta64(1,'s')\n",
    "installs2['sc'] = (installs2['created'] - pd.to_datetime('2019-04-19'))/np.timedelta64(1,'s')\n",
    "installs3['sc'] = (installs3['created'] - pd.to_datetime('2019-04-20'))/np.timedelta64(1,'s')\n",
    "installs4['sc'] = (installs4['created'] - pd.to_datetime('2019-04-21'))/np.timedelta64(1,'s')\n",
    "installs5['sc'] = (installs5['created'] - pd.to_datetime('2019-04-22'))/np.timedelta64(1,'s')\n",
    "installsCheck1['sc'] = (installsCheck1['created'] - pd.to_datetime('2019-04-21'))/np.timedelta64(1,'s')\n",
    "installsCheck2['sc'] = (installsCheck2['created'] - pd.to_datetime('2019-04-22'))/np.timedelta64(1,'s')\n",
    "installsCheck3['sc'] = (installsCheck3['created'] - pd.to_datetime('2019-04-23'))/np.timedelta64(1,'s')\n",
    "installsCheck4['sc'] = (installsCheck4['created'] - pd.to_datetime('2019-04-24'))/np.timedelta64(1,'s')\n",
    "installsCheck5['sc'] = (installsCheck5['created'] - pd.to_datetime('2019-04-25'))/np.timedelta64(1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs1 = installs1.drop_duplicates('ref_hash', keep = 'first')\n",
    "installs2 = installs2.drop_duplicates('ref_hash', keep = 'first')\n",
    "installs3 = installs3.drop_duplicates('ref_hash', keep = 'first')\n",
    "installs4 = installs4.drop_duplicates('ref_hash', keep = 'first')\n",
    "installs5 = installs5.drop_duplicates('ref_hash', keep = 'first')\n",
    "installsCheck1 = installsCheck1.drop_duplicates('ref_hash', keep = 'first')\n",
    "installsCheck2 = installsCheck2.drop_duplicates('ref_hash', keep = 'first')\n",
    "installsCheck3 = installsCheck3.drop_duplicates('ref_hash', keep = 'first')\n",
    "installsCheck4 = installsCheck4.drop_duplicates('ref_hash', keep = 'first')\n",
    "installsCheck5 = installsCheck5.drop_duplicates('ref_hash', keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del installs1['created']\n",
    "del installs2['created']\n",
    "del installs3['created']\n",
    "del installs4['created']\n",
    "del installs5['created']\n",
    "del installsCheck1['created']\n",
    "del installsCheck2['created']\n",
    "del installsCheck3['created']\n",
    "del installsCheck4['created']\n",
    "del installsCheck5['created']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los target ids armo los features de esos ids para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('../datos/target_competencia_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc = target[target['ref_hash'].str.contains('_sc')]\n",
    "targets_st = target[target['ref_hash'].str.contains('_st')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].map(lambda x: str(x)[:-3])\n",
    "targets_sc['ref_hash'] = targets_sc['ref_hash'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_sin_dup = installs.drop_duplicates('ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc_with_installs = targets_sc.merge(installs_sin_dup, how = 'left', on = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.drop_duplicates('ref_hash', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = targets_sc_with_installs[targets_sc_with_installs['created'].isnull()]\n",
    "nulls['ref_type'] = nulls['ref_hash'].map(events.set_index('ref_hash')['ref_type'])\n",
    "nulls['model'] = nulls['ref_hash'].map(events.set_index('ref_hash')['device_model'])\n",
    "nulls['most_freq_lang'] = nulls['ref_hash'].map(events.set_index('ref_hash')['device_language'])\n",
    "nulls['most_freq_app'] = nulls['ref_hash'].map(events.set_index('ref_hash')['application_id'])\n",
    "nulls['ip'] = nulls['ref_hash'].map(events.set_index('ref_hash')['ip_address'])\n",
    "nulls['events_%wifi'] = nulls['ref_hash'].map(eventos.set_index('ref_hash')['wifi'])\n",
    "nulls['event_apps'] = nulls['ref_hash'].map(eventos.set_index('ref_hash')['application_id'])\n",
    "nulls['distinct_events'] = nulls['ref_hash'].map(eventos.set_index('ref_hash')['kind'])\n",
    "nulls['total_events'] = nulls['ref_hash'].map(eventos.set_index('ref_hash')['event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets_sc_with_installs.update(nulls)\n",
    "targets_sc_with_installs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets_sc_with_installs.fillna({'total_apps' : 0, 'ref_type' : 0, '%attributed' : 0, '%implicit': 0, 'model' : 0,\n",
    "                                 'most_freq_lang' : 0, 'ip' : 0, 'events_%wifi' : 0, 'event_apps' : 0, \n",
    "                                 'distinct_events' : 0, 'total_events' : 0, 'most_freq_app' : 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del targets_sc_with_installs['created']\n",
    "del targets_sc_with_installs['obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc_with_installs['most_freq_lang'] = targets_sc_with_installs['most_freq_lang'].astype('float64')\n",
    "X = targets_sc_with_installs[['ref_type', 'ref_hash', 'total_apps', '%implicit', '%attributed', 'most_freq_lang', \n",
    "                             'most_freq_app', 'model', 'ip', 'events_%wifi', 'event_apps', 'distinct_events', \n",
    "                             'total_events']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en _X_ tengo los features necesarios para los ids que quiero predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_pred = pd.read_csv('../datos/PrediccionesKNN-RF-XGBoost.txt', header = None)\n",
    "sc_pred.index = np.arange(1, 8074, 2)\n",
    "targets_sc['obj'] = sc_pred[0]\n",
    "target.update(targets_sc)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv('../datos/preds-xgboost-rf-knn-nuevos-features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo los modelos entrenados en _PromedioPrediccionesSc.ipynb_\n",
    "## XBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el modelo del archivo\n",
    "xg_reg = joblib.load('modelos/sc/xg_reg.pkl')  \n",
    "  \n",
    "predictions_sc_xgb = xg_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = joblib.load('modelos/sc/bagging.pkl')  \n",
    "predictions_sc_bagging = bagging.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = joblib.load('modelos/sc/regr.pkl') \n",
    "predictions_sc_adaboost = regr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = joblib.load('modelos/sc/gbm.pkl')\n",
    "predictions_sc_lgbm = gbm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load('modelos/sc/rf.pkl')\n",
    "predictions_sc_rf = rf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = joblib.load('modelos/sc/nn.pkl')\n",
    "predictions_sc_nn = nn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promedio las predicciones y actualizo el target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sc = np.add(np.add(np.add(np.add(np.add(predictions_sc_xgb,predictions_sc_bagging), predictions_sc_adaboost), predictions_sc_lgbm),predictions_sc_rf), predictions_sc_nn)\n",
    "predictions_sc = predictions_sc / 6\n",
    "targets_sc['obj'] = predictions_sc\n",
    "predicciones_target_sc = target[target['ref_hash'].str.contains('_sc')]\n",
    "predicciones_target_sc['obj'] = predictions_sc\n",
    "target.update(predicciones_target_sc)\n",
    "sc_pred = pd.read_csv('../datos/PrediccionesKNN-RF-XGBoost.txt', header = None)\n",
    "sc_pred.index = np.arange(1, 8074, 2)\n",
    "targets_sc['obj'] = sc_pred[0]\n",
    "target.update(targets_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv('../datos/preds-promedios.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', \n",
    "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha =10, n_estimators = 11)\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=50, learning_rate=0.1)\n",
    "rf = RandomForestRegressor(n_estimators=10, criterion='mse', max_depth=5, min_samples_split=2, \n",
    "                           min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                           max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                           bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n",
    "                           warm_start=False)\n",
    "bagging = BaggingRegressor(KNeighborsRegressor(), max_samples=0.5, max_features=0.5)\n",
    "gbm = lgb.LGBMRegressor(boosting_type= 'gbdt',\n",
    "                        objective= 'regression',\n",
    "                        num_leaves= 31,\n",
    "                        learning_rate= 0.05,\n",
    "                        feature_fraction= 0.9,\n",
    "                        bagging_fraction= 0.8,\n",
    "                        bagging_freq= 5,\n",
    "                        verbose= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventana 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = installsCheck1.iloc[:,:-1], installsCheck1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = installs1.iloc[:,:-1], installs1.iloc[:,-1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='l1', early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_bag = bagging.predict(X_val)\n",
    "preds_lgbm = gbm.predict(X_val)\n",
    "test_preds_xgb = xg_reg.predict(X_test)\n",
    "test_preds_rf = rf.predict(X_test)\n",
    "test_preds_bag = bagging.predict(X_test)\n",
    "test_preds_lgbm = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val['pred_xgb'] = preds_xgb\n",
    "X_val['pred_rf'] = preds_rf\n",
    "X_val['pred_bag'] = preds_bag\n",
    "X_val['pred_lgbm'] = preds_lgbm\n",
    "X_test['pred_xgb'] = test_preds_xgb\n",
    "X_test['pred_rf'] = test_preds_rf\n",
    "X_test['pred_bag'] = test_preds_bag\n",
    "X_test['pred_lgbm'] = test_preds_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_val, y_val)\n",
    "preds = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventana 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = installsCheck2.iloc[:,:-1], installsCheck2.iloc[:,-1]\n",
    "X, y = installs2.iloc[:,:-1], installs2.iloc[:,-1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='l1', early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_bag = bagging.predict(X_val)\n",
    "preds_lgbm = gbm.predict(X_val)\n",
    "test_preds_xgb = xg_reg.predict(X_test)\n",
    "test_preds_rf = rf.predict(X_test)\n",
    "test_preds_bag = bagging.predict(X_test)\n",
    "test_preds_lgbm = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['pred_xgb'] = preds_xgb\n",
    "X_val['pred_rf'] = preds_rf\n",
    "X_val['pred_bag'] = preds_bag\n",
    "X_val['pred_lgbm'] = preds_lgbm\n",
    "X_test['pred_xgb'] = test_preds_xgb\n",
    "X_test['pred_rf'] = test_preds_rf\n",
    "X_test['pred_bag'] = test_preds_bag\n",
    "X_test['pred_lgbm'] = test_preds_lgbm\n",
    "regr.fit(X_val, y_val)\n",
    "preds = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventana 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = installsCheck3.iloc[:,:-1], installsCheck3.iloc[:,-1]\n",
    "X, y = installs3.iloc[:,:-1], installs3.iloc[:,-1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='l1', early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_bag = bagging.predict(X_val)\n",
    "preds_lgbm = gbm.predict(X_val)\n",
    "test_preds_xgb = xg_reg.predict(X_test)\n",
    "test_preds_rf = rf.predict(X_test)\n",
    "test_preds_bag = bagging.predict(X_test)\n",
    "test_preds_lgbm = gbm.predict(X_test)\n",
    "X_val['pred_xgb'] = preds_xgb\n",
    "X_val['pred_rf'] = preds_rf\n",
    "X_val['pred_bag'] = preds_bag\n",
    "X_val['pred_lgbm'] = preds_lgbm\n",
    "X_test['pred_xgb'] = test_preds_xgb\n",
    "X_test['pred_rf'] = test_preds_rf\n",
    "X_test['pred_bag'] = test_preds_bag\n",
    "X_test['pred_lgbm'] = test_preds_lgbm\n",
    "regr.fit(X_val, y_val)\n",
    "preds = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventana 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = installsCheck4.iloc[:,:-1], installsCheck4.iloc[:,-1]\n",
    "X, y = installs4.iloc[:,:-1], installs4.iloc[:,-1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='l1', early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_bag = bagging.predict(X_val)\n",
    "preds_lgbm = gbm.predict(X_val)\n",
    "test_preds_xgb = xg_reg.predict(X_test)\n",
    "test_preds_rf = rf.predict(X_test)\n",
    "test_preds_bag = bagging.predict(X_test)\n",
    "test_preds_lgbm = gbm.predict(X_test)\n",
    "X_val['pred_xgb'] = preds_xgb\n",
    "X_val['pred_rf'] = preds_rf\n",
    "X_val['pred_bag'] = preds_bag\n",
    "X_val['pred_lgbm'] = preds_lgbm\n",
    "X_test['pred_xgb'] = test_preds_xgb\n",
    "X_test['pred_rf'] = test_preds_rf\n",
    "X_test['pred_bag'] = test_preds_bag\n",
    "X_test['pred_lgbm'] = test_preds_lgbm\n",
    "regr.fit(X_val, y_val)\n",
    "preds = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventana 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = installsCheck5.iloc[:,:-1], installsCheck5.iloc[:,-1]\n",
    "X, y = installs5.iloc[:,:-1], installs5.iloc[:,-1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='l1', early_stopping_rounds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(X_val)\n",
    "preds_rf = rf.predict(X_val)\n",
    "preds_bag = bagging.predict(X_val)\n",
    "preds_lgbm = gbm.predict(X_val)\n",
    "test_preds_xgb = xg_reg.predict(X_test)\n",
    "test_preds_rf = rf.predict(X_test)\n",
    "test_preds_bag = bagging.predict(X_test)\n",
    "test_preds_lgbm = gbm.predict(X_test)\n",
    "X_val['pred_xgb'] = preds_xgb\n",
    "X_val['pred_rf'] = preds_rf\n",
    "X_val['pred_bag'] = preds_bag\n",
    "X_val['pred_lgbm'] = preds_lgbm\n",
    "X_test['pred_xgb'] = test_preds_xgb\n",
    "X_test['pred_rf'] = test_preds_rf\n",
    "X_test['pred_bag'] = test_preds_bag\n",
    "X_test['pred_lgbm'] = test_preds_lgbm\n",
    "regr.fit(X_val, y_val)\n",
    "preds = regr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = targets_sc_with_installs[['ref_type', 'ref_hash', 'total_apps', '%implicit', '%attributed', 'most_freq_lang', 'most_freq_app', 'model', 'ip', 'events_%wifi', 'event_apps', 'distinct_events', 'total_events']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = xg_reg.predict(test)\n",
    "preds_rf = rf.predict(test)\n",
    "preds_bag = bagging.predict(test)\n",
    "preds_lgbm = gbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['preds_xgb'] = preds_xgb\n",
    "test['preds_rf'] = preds_rf\n",
    "test['preds_bag'] = preds_bag\n",
    "test['preds_lgbm'] = preds_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sc = regr.predict(test)\n",
    "predictions_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sc['obj'] = predictions_sc\n",
    "predicciones_target_sc = target[target['ref_hash'].str.contains('_sc')]\n",
    "predicciones_target_sc['obj'] = predictions_sc\n",
    "target.update(predicciones_target_sc)\n",
    "sc_pred = pd.read_csv('../datos/PrediccionesKNN-RF-XGBoost.txt', header = None)\n",
    "sc_pred.index = np.arange(1, 8074, 2)\n",
    "targets_sc['obj'] = sc_pred[0]\n",
    "target.update(targets_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv('../datos/preds-blending.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
